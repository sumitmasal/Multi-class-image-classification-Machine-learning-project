# Multi-Class Image Classification 

# 1. Project Overview

The Image Classification of Five Flower Classes project aims to build a machine learning model capable of classifying images of flowers into one of the five predefined classes: **Rose**, **Tulip**, **Sunflower**, **Daisy**, and **Dandelion**. The primary goal is to create a reliable system that can automatically identify and categorize different types of flowers based on input images. The model is designed with a focus on efficiency and lightweight architecture. This project has applications in botany, horticulture, and image recognition tasks.

# 2. Project Structure and Dependencies

## 2.1. Structure

- `requirements.txt`
    - Project dependencies.
- `Codes`
    - `Final_Model.ipynb`
        - Code for **Custom model architecture**.
    - `Trial_Model.ipynb`
        - Code for other models.
- `main.py`
    - This is flask implementation for the project.
- `FINAL_MODEL.rar`
    - This is the model saved as a pickle file and then converted to .rar

## 2.2. Dependencies

Ensure you have the following dependencies installed:

- Python 3.x
- TensorFlow
- NumPy
- Pandas
- Matplotlib and Seaborn
- Scikit-learn
- OpenCV
- Jupyter Notebook

# 3. Dataset Description

- Link for the dataset is given below:
    
    [Flower Classification](https://www.kaggle.com/datasets/sauravagarwal/flower-classification)
    
    
- The dataset used is the one that is already partitioned.

# 4. Data Augmentation

- Data augmentation is a crucial technique in image classification tasks, especially when dealing with limited training data.
- It involves applying various transformations to the original images to create new training samples.
- This process not only increases the size of the training dataset but also helps improve the model's generalization by exposing it to different variations of the same data.
- In this project, data augmentation was applied using the **`ImageDataGenerator`** class provided by the `Keras` library.
- The **`ImageDataGenerator`** allows for on-the-fly data augmentation, ensuring that each batch of images provided to the model during training is slightly different, reducing overfitting and improving the model's ability to generalize to unseen data.
- The following augmentations were used:
    - **Rotation**: Randomly rotates the image by a certain degree.
    - **Width and Height Shift**: Shifts the width and height of the image by a fraction of its total width and height.
    - **Shear**: Applies shear mapping to the image.
    - **Zoom**: Randomly zooms into or out of the image.
    - **Horizontal Flip**: Flips the image horizontally.

# 5. Model Architecture

The model architecture is a custom design that incorporates principles of efficiency, aiming to balance model size and computational efficiency. Key features include the use of depthwise separable convolutions, global average pooling, and dense layers with dropout for classification.

# 6. Training and Evaluation

- Before training, we compiled the model with the following configurations:
    - **Optimizer:** We used the `Adam` optimizer, which is a popular choice for training deep neural networks.
    - **Loss Function:** For this multi-class classification task, we used the `categorical cross-entropy` loss function, which is well-suited for optimizing models that output probability distributions over multiple classes.
- We used a batch size of 16, meaning that the model was updated after processing each batch of 16 images.
- The training process was set to run for 15 epochs, which means that the entire training dataset was processed 15 times.
- We used the test dataset generated by the **`test_generator`** to evaluate the model's performance on previously unseen images.

# 7. Results

The results section provides an overview of the performance and outcomes of our image classification project, including the model's accuracy, visualizations, and any additional insights gained from the experiment.

![Untitled](Results/Trial_Results.png)

![Untitled](Results/Loss.png)

![Untitled](Results/Accuracy.png)

## Final results are as follows:

- The test loss is:  0.8870118856430054
- The best accuracy is:  80.0000011920929

# 8. Deployment

## Flask Implementation

To deploy the image classification model, we have implemented a Flask web application. Flask is a lightweight web framework for Python that allows us to create a web server and serve our machine learning model as an API.

Here's a brief overview of the deployment steps:

1. **Flask Web Application (`main.py`):**
   - The `main.py` file contains the Flask application code. It defines the routes and handles requests.
   - We use the Flask `render_template` function to render the HTML templates and provide the user interface for interacting with the model.

2. **Model Loading (`FINAL_MODEL.pkl`):**
   - The trained model is saved as a pickle file (`final.pkl`).
   - In the Flask application, we load the model using a library like `joblib` or `pickle` at the beginning of the script.

3. **Request Handling:**
   - When a user submits an image through the web interface, the Flask server receives the request.
   - We preprocess the image (resize, normalize, etc.) to match the input requirements of the model.

4. **Model Prediction:**
   - The preprocessed image is passed through the loaded model for prediction.
   - The model predicts the class probabilities, and the Flask application returns the result to the user.

5. **User Interface (`templates` folder):**
   - The `templates` folder contains the HTML templates for the web pages.
   - The user interacts with the deployed model through a simple web interface, where they can upload an image for classification.

## Running the Flask Application Locally

To run the Flask application locally:

```bash
# Navigate to the project directory
cd /path/to/your/project

# Unzip the pickle file if compressed
unzip FINAL_MODEL.pkl.zip

# Run the Flask application
python main.py


